# -*- coding: utf-8 -*-
"""BART_abs.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1m3PRzNLYKL7usRuxE8MUH4FxO8xHYp9u
"""

#!pip install transformers==2.11.0
from ExtractiveSummarizer import summary as extractive_summary
from ExtractiveSummarizer import retention_percentage as extractive_retention_percentage
from ExtractiveSummarizer import no_of_sentences as extractive_num_sentences
from ExtractiveSummarizer import word_count as extractive_word_count
from transformers import BartTokenizer, BartForConditionalGeneration, BartConfig

BART_PATH = 'facebook/bart-large-cnn'

bart_model = BartForConditionalGeneration.from_pretrained(BART_PATH, output_past=True)
bart_tokenizer = BartTokenizer.from_pretrained(BART_PATH, output_past=True)

print("Summary from extractive : {}".format(extractive_summary))
DOCUMENT = extractive_summary

import re

DOCUMENT = re.sub(r'\n|\r', ' ', DOCUMENT)
DOCUMENT = re.sub(r' +', ' ', DOCUMENT)
DOCUMENT = DOCUMENT.strip()

def nest_sentences(document):

  nested = []
  sent = []
  length = 0
  for sentence in nltk.sent_tokenize(document):
    length += len(sentence)
    if length < 1024:
      sent.append(sentence)
    else:
      nested.append(sent)
      sent = []
      length = 0

  if sent:
    nested.append(sent)

  return nested

import nltk
nltk.download('punkt')
nltk.download('stopwords')
nested = nest_sentences(DOCUMENT)

device = 'cuda'

default_error_percentage = 5
min_summary_length = int(((extractive_retention_percentage - default_error_percentage)/100)*extractive_word_count)
max_summary_length = int(((extractive_retention_percentage + default_error_percentage)/100)*extractive_word_count)
print("Min summary length", min_summary_length)
print("Max summary length", max_summary_length)
print("Extractive Retention Percentage", extractive_retention_percentage)
print("Extractive Number of Sentences", extractive_num_sentences)

def generate_summary(nested_sentences):
  device = 'cuda'
  summaries = []
  for nested in nested_sentences:
    input_tokenized = bart_tokenizer.encode(' '.join(nested), truncation=True, return_tensors='pt')
    input_tokenized = input_tokenized.to(device)
    summary_ids = bart_model.to('cuda').generate(input_tokenized,
                                      length_penalty=2.0,
                                      num_beams=4,
                                      no_repeat_ngram_size=3,
                                      min_length=min_summary_length,
                                      max_length = max_summary_length
                                      )
    output = [bart_tokenizer.decode(g, skip_special_tokens=True, clean_up_tokenization_spaces=False) for g in summary_ids]
    summaries.append(output)
  summaries = [sentence for sublist in summaries for sentence in sublist]
  return summaries

summ = generate_summary(nested)

print(summ)
print(len(summ))

